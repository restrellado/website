---
title: 'California School Dashboards Part 3: Modeling the Data '
author: Ryan Estrellado
date: '2018-03-31'
slug: california-school-dashboards-part-3-modeling-the-data
categories: []
tags: [rstats, education]
---



<p><em>This is part three of a three part series where I work with California School Dashboard data by cleaning, visualizaing, and exploring through modeling. You can read the <a href="https://ryanestrellado.netlify.com/post/analyzing-california-school-dashboards-part-1-cleaning/">first part of this series</a>, which shows one way to clean and prepare the data, and <a href="http://ryanestrellado.netlify.com/post/california-school-dashboards-part-2-visualizing-the-data/">the second part of the series</a>, which shows a way to visualize the data .</em></p>
<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>Now that we’ve looked at cleaning the California School Dashboard data and
exploring it through visualization, we’re going to explore it further by looking
at the relationship between math and English language arts scores across subgroups
in nine school districts. We’ll do this by fitting a line through those data points
and visually assessing how well the actual data points resemble that line.</p>
<p>As in the previous two posts, I anonymized the datasets. I won’t include that process
here to keep things brief, but if you’re interested in the procedure I used you can
<a href="https://github.com/restrellado/ca_dashboards_anon/blob/master/join_ela_math.R">view the script</a>
and <a href="https://github.com/restrellado/data_for_blog">cleaned data</a> on my GitHub page.</p>
<p>This approach is inspired by <a href="https://twitter.com/hadleywickham">Hadley Wickham’s</a> “many models” demonstration, which I’ll link to at the end of the post.</p>
</div>
<div id="distance-from-three" class="section level2">
<h2>Distance from Three</h2>
<p>The main number we will be looking at in this analysis is the California School
Dashboard’s “distance from three” score. This is the same score we looked at when
we visualized the dashboard data <a href="http://ryanestrellado.netlify.com/post/california-school-dashboards-part-2-visualizing-the-data/">in part of two of this series</a>. For review, recall that the distance from three score for English language arts is the</p>
<blockquote>
<p>average distance from level 3 of students who took the Smarter Balanced summative assessment in ELA</p>
</blockquote>
<p>If that number is positive the student subgroup performed higher than level three
on average. If that number is negative, the student subgroup performed lower than level
three on average. There’s more on that <a href="https://www.cde.ca.gov/ta/ac/cm/acadindcal.asp">on the CDE website</a> if you’d like to investigate further.</p>
</div>
<div id="do-math-scores-predict-english-language-arts-scores" class="section level2">
<h2>Do Math Scores Predict English Language Arts Scores?</h2>
<p>Let’s explore the first of our nine districts just to see if there’s any hint
of a relationship between the math scores and ELA scores. If we plot the
distance from three score of math on the x-axis and the distance from three
score of English language arts for each school’s subgroup in the first of our
nine districts, we see that there is a pretty clear relationship:</p>
<pre class="r"><code>all_files[[1]] %&gt;% 
  # Remove school level datapoints 
  filter(!is.na(schoolname)) %&gt;%
  ggplot(aes(x = currstatus_math, y = currstatus_ela)) + 
  geom_point() + 
  geom_smooth(method = &quot;lm&quot;) +
  labs(title = &quot;Distance from Three: Math vs. English Language Arts&quot;, 
       x = &quot;Math Dist from Three&quot;, y = &quot;ELA Dist from Three&quot;)</code></pre>
<pre><code>## Warning: Removed 37 rows containing non-finite values (stat_smooth).</code></pre>
<pre><code>## Warning: Removed 37 rows containing missing values (geom_point).</code></pre>
<p><img src="/post/2018-03-28-california-school-dashboards-part-3-modeling-the-data_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<p>Here’s another way to think of it: generally speaking, a subgroup’s difference from
three score in math can help us predict that same subgroup’s difference from three score
in English language arts.</p>
<p>The line drawn through the plot is the model fit. That means that it goes through
the plot in a straight line to best follow the relationship between the math
distance of three and the English language arts distance from three in this
dataset. This relationship is quantified by the model, but we won’t go into that
here because we’re more interested in what this relationship looks like for
different subgroups. But before we get to that, we will need to fit the model
to the nine districts we’re analyzing.</p>
</div>
<div id="fitting-the-model-to-nine-districts" class="section level2">
<h2>Fitting the Model to Nine Districts</h2>
<p>In order to compare this model fit to all nine of our districts, I arranged the
data so that each row was a district and their dataset. I then fit a linear model
to each district and calculated the differences between the predicted values
and actual values. These differences are stored in a column called <code>resid</code>, which is
short for <a href="https://en.wikipedia.org/wiki/Errors_and_residuals">residuals</a>. We’ll
talk a little more about residuals later.</p>
<p>Here is some of the code for arranging the data. Feel free to skip to the plots if
you want to start examing the results.</p>
<p>I used a function for the linear model so I can apply it to all nine datasets
using the <code>purrr</code> package.</p>
<pre class="r"><code>dist_mod &lt;- function(d) {
  lm(currstatus_ela ~ currstatus_math, data = d)
}</code></pre>
<p>Next I used <code>modelr::add_residuals</code> to add the residuals.</p>
<pre class="r"><code>mods &lt;- comb %&gt;% 
  mutate(model = map(data, dist_mod), 
         resids = map2(data, model, add_residuals)) </code></pre>
<p>Finally I used <code>dplyr:unnest</code> to open up the dataset so that each residual
value had it’s own row.</p>
<pre class="r"><code>resids &lt;- mods %&gt;% 
  unnest(resids)</code></pre>
</div>
<div id="the-plots" class="section level2">
<h2>The Plots</h2>
<div id="visualizing-differences-between-subgroups" class="section level3">
<h3>Visualizing Differences Between Subgroups</h3>
<p>Recall that our goal here is to see if there are any differences in our math vs.
ELA relationship when we look at subgroups. The way we’ll do that is to compare how
wrong our linear model got it for each subgroup.</p>
<p>But first a note on missing values:</p>
<p><strong>The original dataset did not include distance from three scores for any subgroup that had less than 11 students. This is a typical practice with education data and is usually done to maintain student confidentiality. Consdquently, there is a pretty sizeable amount of subgroups that are missing distance from three scores. These missing values will be represented as warning messages in R when make our plots. </strong></p>
<p>So let’s see what happens when we remove the math vs. ELA pattern from each dataset and see what we have left over. These are called residual values. (<a href="https://en.wikipedia.org/wiki/Errors_and_residuals">here’s Wikipedia for more reading on residuals</a>). If we create a plot of these leftover
values across distance from three math scores, we get this:</p>
<pre class="r"><code>ggplot(data = resids, aes(x = currstatus_math, y = resid)) + 
  geom_point(alpha = .25) + 
  facet_wrap(~ districtname) + 
  labs(title = &quot;Residuals Across Math Distance From Three Scores&quot;, 
       x = &quot;Math: Distance From Three&quot;, 
       y = &quot;Residuals&quot;)</code></pre>
<pre><code>## Warning: Removed 1356 rows containing missing values (geom_point).</code></pre>
<p><img src="/post/2018-03-28-california-school-dashboards-part-3-modeling-the-data_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>So what does this tell us? The dots closest to <code>y = 0</code> represents where the model predicted ELA results better. A residual of 0 would suggest that there was 0 difference between the predicted and actual values. So the next question is can we see any patterns in leftover values when we examine subgroups? To answer that question we’ll color each subgroup in the plot:</p>
<pre class="r"><code>ggplot(data = resids, aes(x = currstatus_math, y = resid, color = studentgroup)) + 
  geom_point(alpha = .25) + 
  facet_wrap(~ districtname) + 
  labs(title = &quot;Residuals Across Math Distance From Three Scores&quot;, 
       x = &quot;Math: Distance From Three&quot;, 
       y = &quot;Residuals&quot;)</code></pre>
<pre><code>## Warning: Removed 1356 rows containing missing values (geom_point).</code></pre>
<p><img src="/post/2018-03-28-california-school-dashboards-part-3-modeling-the-data_files/figure-html/unnamed-chunk-12-1.png" width="672" /></p>
<p>You can start to see some hints that the subgroup “English Learners Only” had larger residual values in some districts, particularly in <code>district_2</code> and <code>district_7</code>. Recall that leftover values below zero suggest the subgroup had a <em>lower value than expected from the model</em>. Let’s follow this line of questioning and see if we can visually inspect this difference a little more. To do that, we’ll define each subgroup datapoint as either “English Learners Only” or “not English Learners Only”:</p>
<pre class="r"><code>resids %&gt;% 
  mutate(elo = ifelse(studentgroup == &quot;English Learners Only&quot;, &quot;ELO&quot;, &quot;Not ELO&quot;)) %&gt;%
  ggplot(data = ., aes(x = currstatus_math, y = resid, color = elo)) + 
  geom_point(alpha = .5) + 
  facet_wrap(~ districtname) +
  labs(title = &quot;Residuals Across Math Distance From Three Scores&quot;, 
       x = &quot;Math: Distance From Three&quot;, 
       y = &quot;Residuals&quot;, 
       color = &quot;&quot;)</code></pre>
<pre><code>## Warning: Removed 1356 rows containing missing values (geom_point).</code></pre>
<p><img src="/post/2018-03-28-california-school-dashboards-part-3-modeling-the-data_files/figure-html/unnamed-chunk-13-1.png" width="672" /></p>
<p>Now it’s a little clearer that there might be some differences in the way the model fits for the ELO subgroup. We won’t go into the differences in the way the California Department of Education distinguishes ELs from ELOs, but if we were continuing this line of inquiry it would be critical to understand how these subgroups are defined. You can read more about the <a href="https://www.cde.ca.gov/ta/ac/cm/documents/dashboardguidespring17.pdf">definition of EL and ELO in this CDE document</a>.</p>
</div>
</div>
<div id="practical-next-steps" class="section level2">
<h2>Practical Next Steps</h2>
<p>Now that we have this information, what do we do with it? Here are some practical next steps
for building on the analysis like this and turning it into meaningful action:</p>
<p>Build consensus on conclusions by examining other sources of data. Ask questions like:</p>
<ul>
<li>Are there quantitative and anecdotal datasets, like local measures or weekly quiz scores that reinforce or challenge these findings?</li>
<li>Do these findings resonate with the accounts of teachers?</li>
</ul>
<p>Look at the underlying instructional processes that might logically drive these findings. Ask
questions like:</p>
<ul>
<li>What are the similarities and differences in the instructional practices across subgroups?</li>
<li>How can we change instructional practices, even if in small ways, to achieve the outcomes we want for all subgroups?</li>
</ul>
<p>Decide what to try and how to measure. Ask questions like:</p>
<ul>
<li>Once we implement changes, is a repeat of this analysis useful to measure the impact?</li>
<li>If our plan was working, how would we expect the residual data to look different from these results?</li>
</ul>
</div>
<div id="more-on-the-many-models-approach" class="section level2">
<h2>More on the Many Models Approach</h2>
<p>Here’s more on the many models approach as demonstrated by <a href="https://twitter.com/hadleywickham">Hadley Wickham</a>:</p>
<ul>
<li><a href="http://r4ds.had.co.nz/many-models.html">Many Models chapter of R for Data Science</a></li>
<li><a href="https://youtu.be/rz3_FDVt9eg">Hadley Wickham: Managing Many Models With R</a></li>
</ul>
</div>
